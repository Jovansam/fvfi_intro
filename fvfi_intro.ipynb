{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Value Function Iteration\n",
    "\n",
    "Quentin Batista, The University of Tokyo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "1. [The Bellman Operator and the Value Function Iteration (VFI) algorithm](#The-Bellman-Operator)\n",
    "2. [The approximate Bellman Operator and the Fitted Value Function Iteration (FVFI) algorithm](#The-Approximate-Bellman-Operator)\n",
    "3. [Solving the cake eating problem with FVFI in Python](#Python-Implementation)\n",
    "4. [The Curse of Dimensionality](#The-Curse-of-Dimensionality)\n",
    "5. [Brief, high-level discussion of variants on the basic algorithm](#Variants-on-the-Basic-Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bellman Operator\n",
    "\n",
    "We consider the following problem.\n",
    "\n",
    "### Sequential Formulation\n",
    "\n",
    "Let $X$ be a nonempty set.\n",
    "\n",
    "$$\\max_{\\left\\{ x_{t}\\right\\} _{t=1}^{\\infty}}\\sum_{t=0}^{\\infty}\\beta^{t}F\\left(x_{t},x_{t+1}\\right)$$\n",
    "\n",
    "subject to: \n",
    "\n",
    "$$x_{t+1}\\in\\Gamma\\left(x_{t}\\right)\\quad\\text{and}\\quad x_{0}:\\mathrm{given}$$\n",
    "\n",
    "for $t=0,1,\\dots$.\n",
    "\n",
    "- $x_{t}$: state vector\n",
    "- $\\Gamma:X\\rightarrow X$: feasibility constraint (correspondence)\n",
    "- $F:A\\rightarrow\\mathbb{R}$ where $A=\\left\\{ \\left(x,y\\right)\\in X\\times X:y\\in\\Gamma\\left(x\\right)\\right\\} $: one-period return function\n",
    "- $\\beta\\in\\left(0,1\\right)$: discount factor\n",
    "\n",
    "\n",
    "### Application to the Cake Eating Problem from the QuantEcon lecture\n",
    "\n",
    "Consider the setup from the [Cake Eating Problem QuantEcon lecture](https://python-intro.quantecon.org/cake_eating_problem.html).\n",
    "\n",
    "\n",
    "$$\\max_{\\left\\{ c_{t}\\right\\} _{t=0}^{\\infty}}\\sum_{t=0}^{\\infty}\\beta^{t}u\\left(c_{t}\\right) \\tag{1}$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - c_t\n",
    "\\quad \\text{and} \\quad\n",
    "0\\leq c_t\\leq x_t \\tag{2}\n",
    "$$\n",
    "\n",
    "\n",
    "for $t=0,1,\\dots$.\n",
    "\n",
    "- $x_{t}$: size of the cake at time $t$\n",
    "- $c_{t}$: choice of consumption at time $t$\n",
    "- Law of motion: $x_{t+1}=x_{t}-c_{t}$\n",
    "- Time 0 endowment: $x_{0}=\\bar{x}$\n",
    "- $u\\left(c\\right)=\\frac{c^{1-\\gamma}}{1-\\gamma}$: utility function\n",
    "- $\\beta$: discount factor\n",
    "- $\\Gamma\\left(x\\right)=\\left\\{ y\\in\\mathbb{R}_{+}:y=x-c\\:\\mathrm{for}\\:\\mathrm{some}\\:c\\in\\left[0,x\\right]\\right\\}  $\n",
    "- $F\\left(x,y\\right)=u\\left(x-y\\right)$\n",
    "\n",
    "### Some Helpful Assumptions\n",
    "\n",
    "1. $X\\subset\\mathbb{R}^{N}$\n",
    "2. $F$: continuous\n",
    "3. $F$: bounded\n",
    "\n",
    "*Note: many examples from Economics require some modifications to satisfy assumption 3.*\n",
    "\n",
    "### Recursive Formulation\n",
    "\n",
    "#### A crucial observation\n",
    "\n",
    "Denote $\\Pi\\left(x_{0}\\right)=\\left\\{ \\left\\{ x_{t}\\right\\} _{t=0}^{\\infty}:x_{t+1}\\in\\Gamma\\left(x_{t}\\right),t=0,1,\\dots\\right\\} $.\n",
    "\n",
    "This is the set of feasible paths.\n",
    "\n",
    "Let $U\\left(\\underline{x}\\right)=\\sum_{t=0}^{\\infty}\\beta^{t}F\\left(x_{t},x_{t+1}\\right)$ where $\\underline{x}=\\left(x_{0},x_{1},\\dots\\right)$ and $\\underline{x}^{t}=\\left(x_{t},x_{t+1},\\dots\\right)$.\n",
    "\n",
    "Observe that:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "U\\left(\\underline{x}\\right)&=&F\\left(x_{0},x_{1}\\right)+\\sum_{t=1}^{\\infty}\\beta^{t}F\\left(x_{t},x_{t+1}\\right)\\\\&=&F\\left(x_{0},x_{1}\\right)+\\beta U\\left(\\underline{x}^{1}\\right)\\\\&=&F\\left(x_{0},x_{1}\\right)+\\beta F\\left(x_{0},x_{1}\\right)+\\beta^{2}U\\left(\\underline{x}^{2}\\right)\\\\&\\vdots&\\\\&=&\\sum_{\\tau=0}^{t-1}\\beta^{\\tau}F\\left(x_{\\tau},x_{\\tau+1}\\right)+\\beta^{t}U\\left(\\underline{x}^{t}\\right)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "#### Optimal value function\n",
    "\n",
    "Let: \n",
    "\n",
    "$$v^{*}\\left(x\\right)=\\sup_{\\underline{x}\\in\\Pi\\left(x\\right)}U\\left(\\underline{x}\\right)$$\n",
    "\n",
    "($v^{*}$ is well-defined and bounded by assumption 3.)\n",
    "\n",
    "In the cake eating problem, $v^{*}$ is the maximum lifetime utility attainable from the current time when $x$ units of cake are left.\n",
    "\n",
    "Using our \"crucial observation\":\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "v^{*}\\left(x\\right)&=&\\sup_{\\underline{x}\\in\\Pi\\left(x\\right)}U\\left(\\underline{x}\\right)\\\\&=&\\sup_{\\underline{x}\\in\\Pi\\left(x\\right)}F\\left(x,y\\right)+\\beta U\\left(\\underline{x}^{1}\\right)\\\\&=&\\sup_{y\\in\\Gamma\\left(x\\right)}F\\left(x,y\\right)+\\beta\\sup_{\\underline{x}\\in\\Pi\\left(y\\right)}U\\left(\\underline{x}\\right)\\\\&=&\\sup_{y\\in\\Gamma\\left(x\\right)}F\\left(x,y\\right)+\\beta v^{*}\\left(y\\right)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "This equation is called the Bellman equation.\n",
    "\n",
    "### The Bellman Operator\n",
    "\n",
    "Let $\\mathcal{B}\\left(X\\right)$ be the set of bounded functions from $X$ to $\\mathbb{R}$ and $\\mathcal{C}_{b}\\left(X\\right)$ the set of bounded countinuous functions from $X$ to $\\mathbb{R}$.\n",
    "\n",
    "Given $v\\in\\mathcal{B}\\left(X\\right)$, let\n",
    "\n",
    "$$w\\left(x\\right)\\equiv\\sup_{y\\in\\Gamma\\left(x\\right)}F\\left(x,y\\right)+\\beta v\\left(y\\right)$$ \n",
    "\n",
    "One can show that $w\\in\\mathcal{B}\\left(X\\right)$.\n",
    "\n",
    "We can regard the right-hand side of this equation as a function of $v$. Using this observation, we can define the operator $T:\\mathcal{B}\\left(X\\right)\\rightarrow\\mathcal{B}\\left(X\\right)$ satisfying:\n",
    "\n",
    "$$\\left(Tv\\right)\\left(x\\right)=\\sup_{y\\in\\Gamma\\left(x\\right)}F\\left(x,y\\right)+\\beta v\\left(y\\right)$$\n",
    "\n",
    "This operator is called the Bellman operator.\n",
    "\n",
    "(If $v\\in\\mathcal{C}_{b}\\left(X\\right)$, we can replace $\\sup$ with $\\max$ (by the Extreme Value Theorem) and $Tv\\in\\mathcal{C}_{b}\\left(X\\right)$ (by the Theorem of Maximum).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function Iteration Algorithm\n",
    "\n",
    "Observe that $Tv^{*}=v^{*}$, i.e. $v^{*}$ is a fixed point of $T$ \n",
    "\n",
    "**Idea:** Start with some function $v$ and apply $T$ repeatedly until convergence\n",
    "\n",
    "<img src=\"vfi_algo.jpeg\">\n",
    "\n",
    "where $bS=\\mathcal{B}\\left(X\\right)$ in our notation and $d_{\\infty}\\left(v,w\\right)=\\sup_{x\\in X}\\left|v\\left(x\\right)-w\\left(x\\right)\\right|$. \n",
    "\n",
    "*Source: Chapter 5 of [1]*\n",
    "\n",
    "A stopping criterion is used to avoid iterating for an infinite amount of time.\n",
    "\n",
    "#### How does this work?\n",
    "\n",
    "1. Show that $T$ is a **contraction mapping** in $\\left(\\mathcal{B}\\left(X\\right),d_{\\infty}\\right)$, i.e. $d_{\\infty}\\left(Tv,Tw\\right)\\leq\\beta d_{\\infty}\\left(v,w\\right)$\n",
    "2. Show that $\\left(\\mathcal{B}\\left(X\\right),d_{\\infty}\\right)$ is a complete metric space (see [here](https://en.wikipedia.org/wiki/Complete_metric_space#Some_theorems))\n",
    "3. Apply [Banach's fixed point theorem](https://en.wikipedia.org/wiki/Banach_fixed-point_theorem)\n",
    "\n",
    "Result: $T^{n}v$ converges (uniformly) to $v^{*}$ as $n\\rightarrow\\infty$\n",
    "\n",
    "#### Error bound and rate of convergence\n",
    "\n",
    "Using the fact that $T$ is a contraction mapping:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "d_{\\infty}\\left(T^{2}v,Tv\\right)&\\leq&\\beta d_{\\infty}\\left(Tv,v\\right)\\\\d_{\\infty}\\left(T^{3}v,T^{2}v\\right)&\\leq&\\beta d_{\\infty}\\left(T^{2}v,Tv\\right)\\\\&\\vdots&\\\\d_{\\infty}\\left(T^{n}v,T^{n-1}v\\right)&\\leq&\\beta d_{\\infty}\\left(T^{n-1}v,T^{n-2}v\\right)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "This gives us some information about the speed of convergence of the algorithm and helps us form expectation about what a \"normal\" error pattern should look like. ($\\beta$ is called a Lipschitz constant for $T$)\n",
    "\n",
    "We can also show that:\n",
    "\n",
    "$$d_{\\infty}\\left(v^{*},Tv\\right)\\leq\\frac{\\beta}{1-\\beta}d_{\\infty}\\left(Tv,v\\right)$$\n",
    "\n",
    "This gives us a bound for the approximation error arising from using a stopping criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy function\n",
    "\n",
    "Assume that the agent chooses $x_{t+1}$ according to $x_{t+1}=\\sigma\\left(x_{t}\\right)$ for some  $\\sigma:X \\rightarrow X$.\n",
    "\n",
    "$\\sigma$ is called a **policy function**. \n",
    "\n",
    "\n",
    "Let $v_{\\sigma}$ be the value associated with following policy $\\sigma$.\n",
    "\n",
    "A policy is feasible if it satisfies $\\sigma\\left(x\\right)\\in\\Gamma\\left(x\\right)$ for all $x$. Let $\\Sigma$ denote the set of all feasible policies.\n",
    "\n",
    "Observe that:\n",
    "\n",
    "$$v^{*}\\left(x\\right)=\\sup\\left\\{ v_{\\sigma}\\left(x\\right):\\sigma\\in\\Sigma\\right\\} $$\n",
    "\n",
    "$\\sigma^{*}$ is called an optimal policy function if $v_{\\sigma^{*}}=v^{*}$\n",
    "\n",
    "As we did with the Bellman operator, we can define an operator $T_{\\sigma}$ satisfying\n",
    "\n",
    "$$\\left(T_{\\sigma}v\\right)\\left(x\\right)=F\\left(x,\\sigma\\left(x\\right)\\right)+\\beta v\\left(\\sigma\\left(x\\right)\\right)$$\n",
    "\n",
    "Iteration on $T_{\\sigma}$ converges to $v_{\\sigma}$. \n",
    "\n",
    "A policy $\\sigma$ is $v$-greedy if it satisfies\n",
    "\n",
    "$$\\sigma\\left(x\\right)\\in\\arg\\max_{y\\in\\Gamma\\left(x\\right)}F\\left(x,y\\right)+\\beta v\\left(y\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Approximate Bellman Operator\n",
    "\n",
    "Computers generally use floating point arithmetic (i.e. use a string of 1 and 0 of fixed length, say 32 or 64, to approximate real numbers) so some degree of approximation is always necessary.  \n",
    "\n",
    "Computers have finite amount of memory so it is in general not possible to store $v\\left(x\\right)$ for all $x\\in\\mathbb{R}_{+}$.\n",
    "\n",
    "#### Challenge: How can we represent $v$ on a computer?\n",
    "\n",
    "- Parametric approximation to $v$, say with a polynomial function $w\\left(y\\right)=\\sum_{i=0}^{n-1}a_{i}y^{i}$\n",
    "- Consider only a finite set of points in $\\mathbb{R_{+}}$\n",
    "\n",
    "This generates additional **approximation** error\n",
    "\n",
    "### Fitted Value Function Iteration\n",
    "\n",
    "Let $\\hat{T}$ be an approximate Bellman operator. \n",
    "\n",
    "We have the following decomposition: $\\hat{T}=L\\circ T$, i.e. $\\hat{T}v=LTv$.\n",
    "\n",
    "- $T$ is the Bellman operator.\n",
    "- $L$ is an approximation operator\n",
    "\n",
    "**Idea:** Iterate on the approximate Bellman operator until convergence.\n",
    "\n",
    "<img src=\"fvfi_algo.jpeg\">\n",
    "\n",
    "*Source: Chapter 6 of [1]*\n",
    "\n",
    "#### Fitted Value Function Iteration + Piecewise Constant Linear Interpolation + Grid\n",
    "\n",
    "In this lecture, we'll mostly focus on the following scheme: \n",
    "\n",
    "- Equally spaced grid of points \n",
    "- Piecewise linear interpolation \n",
    "- Constant extrapolation\n",
    "\n",
    "<img src=\"illustration_basic_scheme.jpeg\" width='600'>\n",
    "\n",
    "**FVFI specialized to the Cake Eating Problem:**\n",
    "\n",
    "<img src=\"specialized_fvfi.png\">\n",
    "\n",
    "\n",
    "#### How do we know that value iteration will still work when there is approximation error?\n",
    "\n",
    "If $L$ is **nonexpansive** on $\\left(\\mathcal{C}_{b}\\left(X\\right),d_{\\infty}\\right)$, $\\hat{T}$ is a uniform contraction on $\\left(\\mathcal{C}_{b}\\left(X\\right),d_{\\infty}\\right)$ and the previous line of reasoning applies. (See [6])\n",
    "\n",
    "$L$ is **nonexpansive** on $\\left(S,d\\right)$ if \n",
    "\n",
    "$$d\\left(Lv,Lw\\right)\\leq d\\left(v,w\\right)$$ \n",
    "\n",
    "for all $v,w\\in S$. \n",
    "\n",
    "The approximation scheme described above is nonexpansive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Comments on FVFI\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- Extremely versatile\n",
    "- Theoretical properties\n",
    "- Global solution\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "- Slow (compared to say perturbation methods)\n",
    "- Often suffers from the Curse of Dimensionality\n",
    "- Interaction between different approximation at different levels can sometimes cause instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Implementation\n",
    "\n",
    "### Some comments on programming language\n",
    "\n",
    "Many people have strong opinions about which language is better.\n",
    "\n",
    "**Advantages of Matlab:**\n",
    "- Currently mainstream in Economics (legacy code is often in Matlab)\n",
    "\n",
    "**Disadvantages of Matlab:**\n",
    "- Closed-source\n",
    "- Often slow\n",
    "- Design\n",
    "\n",
    "**Advantages of Python:**\n",
    "- Well-developed ecosystem\n",
    "- Extremely versatile\n",
    "- Object-orientated language\n",
    "\n",
    "**Disadvantages of Python:**\n",
    "- Getting different tools to work together can be difficult\n",
    "\n",
    "**Advantages of Julia:**\n",
    "- Built for scientific computation\n",
    "- Dynare developers are working on a Julia version\n",
    "\n",
    "**Disadvantages of Julia:**\n",
    "- Changing very quickly\n",
    "\n",
    "\n",
    "Some people argue that Python is too slow for computational Economics (e.g. [Aruoba and Fernandez-Villaverde](https://github.com/jstac/julia_python_comparison/blob/master/Update_March_23_2018.pdf))\n",
    "\n",
    "Answer: [No, Python is Not Too Slow for Computational Economics](https://notes.quantecon.org/submission/5bae5cb538674f000fd2c8e3) by John Stachurski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python tools for scientific computation\n",
    "\n",
    "- [NumPy](https://numpy.org/devdocs/reference/index.html): Data structure for numerical computation + some linear algebra\n",
    "- [SciPy](https://docs.scipy.org/doc/scipy/reference/): Scientific computation from solving optimization problem, linear algebra, interpolation, solving differential equations, etc...\n",
    "- [Pandas](https://pandas.pydata.org/): Data structure + tools for data analysis\n",
    "- [Matplotlib](https://matplotlib.org/): Plotting library\n",
    "- [SymPy](https://www.sympy.org/en/index.html): Symbolic computation\n",
    "- [Numba](http://numba.pydata.org/): Makes your code fast\n",
    "- [Interpolation](https://github.com/EconForge/interpolation.py): Fast interpolation \n",
    "- [JAX](https://github.com/google/jax): Automatic differentiation + code optimization\n",
    "\n",
    "### Some Python tools for economic modelling\n",
    "\n",
    "- [QuantEcon.py](https://quanteconpy.readthedocs.io/en/latest/): Tools to support your own code (e.g. discretization of AR(1) process, LQ control problems, some optimizers, etc...).\n",
    "- [Dolo](https://dolo.readthedocs.io/en/latest/): More or less equivalent to `Dynare`.\n",
    "- [Econ-ARK](https://econ-ark.org/): Toolkit for heterogenuous agents structural modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install interpolation matplotlib quantecon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from interpolation import interp\n",
    "from scipy.optimize import minimize_scalar, minimize, curve_fit\n",
    "from numba import njit, prange \n",
    "from quantecon.optimize import scalar_maximization\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Mathematics is the art of giving the same thing different names\" (Henri Poincaré)\n",
    "\n",
    "class CakeEating:\n",
    "    def __init__(self,\n",
    "                 β=0.96,           # discount factor\n",
    "                 γ=1.5,            # degree of relative risk aversion\n",
    "                 x_grid_min=1e-3,  # exclude zero for numerical stability\n",
    "                 x_grid_max=2.5,   # size of cake\n",
    "                 x_grid_size=120):\n",
    "\n",
    "        self.β, self.γ = β, γ\n",
    "\n",
    "        # Set up grid\n",
    "        self.x_grid = np.linspace(x_grid_min, x_grid_max, x_grid_size)\n",
    "\n",
    "    # Utility function\n",
    "    def u(self, c):\n",
    "\n",
    "        γ = self.γ\n",
    "\n",
    "        if γ == 1:\n",
    "            return np.log(c)\n",
    "        else:\n",
    "            return (c ** (1 - γ)) / (1 - γ)\n",
    "\n",
    "    # first derivative of utility function\n",
    "    def u_prime(self, c):\n",
    "\n",
    "        return c ** (-self.γ)\n",
    "\n",
    "    def state_action_value(self, c, x, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation given x and c.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        u, β = self.u, self.β\n",
    "        v = lambda x: interp(self.x_grid, v_array, x)\n",
    "\n",
    "        return u(c) + β * v(x - c)\n",
    "    \n",
    "\n",
    "# Define a function to solve the maximization problem\n",
    "def maximize(g, a, b, args):\n",
    "    \"\"\"\n",
    "    Maximize the function g over the interval [a, b].\n",
    "\n",
    "    We use the fact that the maximizer of g on any interval is\n",
    "    also the minimizer of -g.  The tuple args collects any extra\n",
    "    arguments to g.\n",
    "\n",
    "    Returns the maximal value and the maximizer.\n",
    "    \"\"\"\n",
    "\n",
    "    objective = lambda x: -g(x, *args)\n",
    "    result = minimize_scalar(objective, bounds=(a, b), method='bounded')\n",
    "    maximizer, maximum = result.x, -result.fun\n",
    "    return maximizer, maximum\n",
    "\n",
    "\n",
    "def T(v, ce):\n",
    "    \"\"\"\n",
    "    The Bellman operator.  Updates the guess of the value function.\n",
    "\n",
    "    * ce is an instance of CakeEating\n",
    "    * v is an array representing a guess of the value function\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "\n",
    "    for i, x in enumerate(ce.x_grid):\n",
    "        # Maximize RHS of Bellman equation at state x\n",
    "        v_new[i] = maximize(ce.state_action_value, 1e-10, x, (x, v))[1]  # v_new[i] = v'(x_i)\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the `CakeEating` class\n",
    "# ce.β\n",
    "ce = CakeEating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a plot showing how the value function changes at each iteration\n",
    "x_grid = ce.x_grid\n",
    "v = ce.u(x_grid)       # Initial guess\n",
    "n = 12                 # Number of iterations\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, color=plt.cm.jet(0),\n",
    "        lw=2, alpha=0.6, label='Initial guess')\n",
    "\n",
    "for i in range(n):\n",
    "    v = T(v, ce)  # Apply the Bellman operator\n",
    "    ax.plot(x_grid, v, color=plt.cm.jet(i / n), lw=2, alpha=0.6)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('value', fontsize=12)\n",
    "ax.set_xlabel('cake size $x$', fontsize=12)\n",
    "ax.set_title('Value function iterations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_value_function(ce,\n",
    "                           tol=1e-4,\n",
    "                           max_iter=1000,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    # Set up loop\n",
    "    v = np.zeros(len(ce.x_grid)) # Initial guess\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:  # `max_iter` is used to ensure termination of algorithm\n",
    "        v_new = T(v, ce)\n",
    "\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"Error at iteration {i} is {error}.\")\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    if i == max_iter:\n",
    "        print(\"Failed to converge!\")\n",
    "\n",
    "    if verbose and i < max_iter:\n",
    "        print(f\"\\nConverged in {i} iterations.\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "v = compute_value_function(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute analytical solution at grid points\n",
    "def v_star(x, β, γ):\n",
    "    return (1 - β**(1 / γ))** (-γ) * (x ** (1-γ) / (1-γ))\n",
    "\n",
    "\n",
    "v_analytical = v_star(ce.x_grid, ce.β, ce.γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a plot that compares the numerical and analytical solutions\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v_analytical, label='analytical solution')\n",
    "ax.plot(x_grid, v, label='numerical solution')\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_title('Comparison between analytical and numerical value functions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def σ(ce, v):\n",
    "    \"\"\"\n",
    "    The optimal policy function. Given the value function,\n",
    "    it finds optimal consumption in each state.\n",
    "\n",
    "    * ce is an instance of CakeEating\n",
    "    * v is a value function array\n",
    "\n",
    "    \"\"\"\n",
    "    c = np.empty_like(v)\n",
    "\n",
    "    for i in range(len(ce.x_grid)):\n",
    "        x = ce.x_grid[i]\n",
    "        # Maximize RHS of Bellman equation at state x\n",
    "        c[i] = maximize(ce.state_action_value, 1e-10, x, (x, v))[0]\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "c = σ(ce, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_star(x, β, γ):\n",
    "\n",
    "    return (1 - β ** (1/γ)) * x\n",
    "\n",
    "\n",
    "c_analytical = c_star(ce.x_grid, ce.β, ce.γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ce.x_grid, c_analytical, label='analytical')\n",
    "ax.plot(ce.x_grid, c, label='Numerical')\n",
    "ax.set_ylabel(r'$\\sigma(x)$')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x'\n",
    "ce.x_grid[0] - c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(x) \n",
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(x')\n",
    "interp(ce.x_grid, v, ce.x_grid[0] - c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality\n",
    "\n",
    "We ask the following question: how does the number of points in our grid change when we increase the number of dimensions of the state vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_nb = 12\n",
    "d = np.arange(1, dims_nb)\n",
    "points_per_d = 10\n",
    "grid_points = points_per_d ** d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d, grid_points, 'o');\n",
    "plt.xlabel('number of dimensions')\n",
    "plt.ylabel('total numer of grid points')\n",
    "# 1e11 = one hundred billion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both memory requirements and the amount of computation explode exponentially as the number of dimensions grow!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many economic models feature high-dimensional state spaces:\n",
    "- International Real Business Cycle models\n",
    "- Dynamic Stochastic General Equilibrium (DSGE) models\n",
    "- Overlapping Generations (OLG) models\n",
    "- Mathematical finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU-bound\n",
    "\n",
    "\"In computer science, a computer is CPU-bound (or compute-bound) when the time for it to complete a task is determined principally by the speed of the central processor: processor utilization is high, perhaps at 100% usage for many seconds or minutes. \" (Wikipedia)\n",
    "\n",
    "### Memory-bound\n",
    "\n",
    "\"Memory bound refers to a situation in which the time to complete a given computational problem is decided primarily by the amount of memory required to hold data.\" (Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_nb = 20\n",
    "\n",
    "try:\n",
    "    np.ones((points_per_d, ) * dims_nb)\n",
    "except ValueError as e: \n",
    "    print('Error message:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants on the Basic Algorithm\n",
    "\n",
    "### Different Numerical Grids\n",
    "\n",
    "**Basic idea**: Choose points in a more thoughtful manner\n",
    "\n",
    "- `np.geomspace` vs. `np.linspace`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_grid = np.geomspace(ce.x_grid.min(), ce.x_grid.max(), num=ce.x_grid.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "idx = np.arange(0, ce.x_grid.size)\n",
    "plt.plot(idx, ce.x_grid, 'o', markersize=2., label='np.linspace')\n",
    "plt.plot(idx, geom_grid, 'o', markersize=2., label='geomspace')\n",
    "plt.xlabel('index', size=16)\n",
    "plt.ylabel(r'$x$', size=16)\n",
    "plt.legend()\n",
    "plt.title('np.linspace vs np.geomspace');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_geom = CakeEating()\n",
    "ce_geom.x_grid = geom_grid  # Modifies the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_geom = compute_value_function(ce_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.plot(x_grid, v, label='np.linspace')\n",
    "ax.plot(x_grid, interp(geom_grid, v_geom, x_grid), label='np.geomspace')\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fancy: [Adaptive sparse grids](http://johannesbrumm.com/wp-content/uploads/2017/09/Brumm-Scheidegger-2017-ECTA.pdf)\n",
    "\n",
    "<img src=\"full_vs_sparse_grid.png\" width=\"400\">\n",
    "\n",
    "<img src=\"adaptive_sparse_test.png\"  width=\"1000\">\n",
    "\n",
    "*Source: [2]*\n",
    "\n",
    "**Important note:** There are grid-free methods for doing numerical DP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Approximation Methods\n",
    "\n",
    "Packages in Python: [interpolation.py](https://github.com/EconForge/interpolation.py), [SciPy](https://docs.scipy.org/doc/scipy/reference/interpolate.html)\n",
    "\n",
    "- Piecewise linear\n",
    "- Various types of polynomials ([Chebychev](https://en.wikipedia.org/wiki/Chebyshev_polynomials), [Hermite](https://en.wikipedia.org/wiki/Hermite_polynomials))\n",
    "- [Splines](https://en.wikipedia.org/wiki/Spline_(mathematics)) (i.e. piecewise polynomial)\n",
    "- Neural Networks (tools: [TensorFlow](https://github.com/tensorflow/tensorflow), [PyTorch](https://github.com/pytorch/pytorch), [Keras](https://keras.io/))\n",
    "\n",
    "If you **really** love neural networks: [DeepEquilibriumNets](https://github.com/sischei/DeepEquilibriumNets)\n",
    "\n",
    "On Neural Networks: \n",
    "- Very popular recently\n",
    "\n",
    "#### Things to take into consideration:\n",
    "\n",
    "- Nonexpansive approximation\n",
    "- Shape preservation (see [7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Consider the following functional form: $w_{i}\\left(y\\right)\\equiv w\\left(y;a_{i},b_{i}\\right)=a_{i}y^{b_{i}}$.\n",
    "\n",
    "(Recall the analytical solution is $v^{*}\\left(x\\right)=\\left(1-\\beta^{\\frac{1}{\\gamma}}\\right)^{-\\gamma}\\frac{x^{1-\\gamma}}{1-\\gamma}$) \n",
    "\n",
    "#### Procedure\n",
    "\n",
    "Start with $a_{0}$ and $b_{0}$. \n",
    "\n",
    "Compute $\\hat{T}v_{i+1}\\left(x\\right)=\\max_{c\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c\\right)+\\beta w_{i}\\left(x-c\\right)\\right\\} $ for all $x$.\n",
    "\n",
    "Compute $w_{i+1}$ by solving $\\min_{\\left(a_{i+1},b_{i+1}\\right)}N^{-1}\\sum_{j=1}^{N}\\left(w\\left(x_{j};a_{i+1},b_{i+1}\\right)-\\hat{T}v_{i+1}\\left(x_{j}\\right)\\right)^{2}$.  (We'll use `scipy.optimize.curve_fit` in Python)\n",
    "\n",
    "Iterate until convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w(y, a, b):  # New function\n",
    "    return a * y ** b\n",
    "\n",
    "\n",
    "def T(v, ce, a, b):  # Changed here\n",
    "    \"\"\"\n",
    "    The Bellman operator.  Updates the guess of the value function.\n",
    "\n",
    "    * ce is an instance of CakeEating\n",
    "    * v is an array representing a guess of the value function\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "\n",
    "    for i, x in enumerate(ce.x_grid):\n",
    "        # Maximize RHS of Bellman equation at state x\n",
    "        objective = lambda c, a, b: ce.u(c) + ce.β * w(x - c, a, b)  # Changed here\n",
    "        v_new[i] = maximize(objective, 1e-10, x, (a, b))[1]\n",
    "        \n",
    "    a_new, b_new = curve_fit(w, x_grid, v_new)[0]  # Changed here\n",
    "\n",
    "    return v_new, a_new, b_new  # Changed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_value_function(ce,\n",
    "                           tol=1e-4,\n",
    "                           max_iter=1000,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    # Set up loop\n",
    "    v = np.zeros(len(ce.x_grid)) # Initial guess\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    a, b = 1, 1.  # New variables\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new, a, b = T(v, ce, a, b)  # Changed here\n",
    "\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"Error at iteration {i} is {error}.\")\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    if i == max_iter:\n",
    "        print(\"Failed to converge!\")\n",
    "\n",
    "    if verbose and i < max_iter:\n",
    "        print(f\"\\nConverged in {i} iterations.\")\n",
    "\n",
    "    return v_new, a, b  # Changed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_param, a, b = compute_value_function(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v_analytical, label='analytical solution')\n",
    "ax.plot(x_grid, v_param, label='numerical solution')\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_title('Comparison between analytical and numerical value functions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Maximization Routines\n",
    "\n",
    "- [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)\n",
    "- [quantecon.optimize](https://quanteconpy.readthedocs.io/en/latest/optimize.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to solve the maximization problem\n",
    "def maximize(g, x0, args):  # Changed here\n",
    "    \"\"\"\n",
    "    Maximize the function g over the interval [a, b].\n",
    "\n",
    "    We use the fact that the maximizer of g on any interval is\n",
    "    also the minimizer of -g.  The tuple args collects any extra\n",
    "    arguments to g.\n",
    "\n",
    "    Returns the maximal value and the maximizer.\n",
    "    \"\"\"\n",
    "\n",
    "    objective = lambda x: -g(x, *args)\n",
    "    # Previously: result = minimize_scalar(objective, bounds=(a, b), method='bounded')\n",
    "    result = minimize(objective, x0, bounds=[[1e-10, args[0]]], method='L-BFGS-B')  # Changed here\n",
    "    maximizer, maximum = result.x, -result.fun\n",
    "    return maximizer, maximum\n",
    "\n",
    "\n",
    "def T(v, ce):\n",
    "    \"\"\"\n",
    "    The Bellman operator.  Updates the guess of the value function.\n",
    "\n",
    "    * ce is an instance of CakeEating\n",
    "    * v is an array representing a guess of the value function\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "\n",
    "    for i, x in enumerate(ce.x_grid):\n",
    "        # Maximize RHS of Bellman equation at state x\n",
    "        x0 = x / 10\n",
    "        v_new[i] = maximize(ce.state_action_value, x0, (x, v))[1]  # Changed here\n",
    "\n",
    "    return v_new\n",
    "\n",
    "\n",
    "def compute_value_function(ce,\n",
    "                           tol=1e-4,\n",
    "                           max_iter=1000,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    # Set up loop\n",
    "    v = np.zeros(len(ce.x_grid)) # Initial guess\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new = T(v, ce)\n",
    "\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"Error at iteration {i} is {error}.\")\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    if i == max_iter:\n",
    "        print(\"Failed to converge!\")\n",
    "\n",
    "    if verbose and i < max_iter:\n",
    "        print(f\"\\nConverged in {i} iterations.\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "v_diff_optimizer = compute_value_function(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, label='original optimizer')\n",
    "ax.plot(x_grid, v_diff_optimizer, label='new optimizer')\n",
    "#ax.plot(x_grid, v_analytical, label='analytical')\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_title('Comparison between analytical and numerical value functions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "\n",
    "\"The approximate $|S|$ of\n",
    "chess, shogi, and Go are $10^{47}$, $10^{71}$, and $10^{171}$, respectively, which are comparable to the\n",
    "number of atoms in the observable universe ($10^{78}$ ∼ $10^{82}$) and certainly larger than the total\n",
    "information-storage capacity of humanity (in the order of $10^{20}$ bytes).\" (Igami, 2018)\n",
    "\n",
    "\n",
    "<img src=\"fig_8_sutton_barto.png\">\n",
    "\n",
    "*Source: [4]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exhaustive Search Direction\n",
    "\n",
    "Expand the Bellman equation:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "v\\left(x\\right)&=&\\max_{c\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c\\right)+\\beta v\\left(x-c\\right)\\right\\} \\\\&=&\\max_{c_{1}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{1}\\right)+\\beta\\max_{c_{2}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{2}\\right)+\\beta v\\left(x-c_{1}-c_{2}\\right)\\right\\} \\right\\} \\\\&=&\\max_{c_{1}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{1}\\right)+\\beta\\max_{c_{2}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{2}\\right)+\\beta\\max_{c_{3}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{3}\\right)+\\beta v\\left(x-c_{1}-c_{2}-c_{3}\\right)\\right\\} \\right\\} \\right\\} \n",
    "\\end{eqnarray}$$\n",
    "\n",
    "You can repeat this as many times as you want.\n",
    "\n",
    "Let $T'v\\left(x\\right)=\\max_{c_{1}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{1}\\right)+\\beta\\max_{c_{2}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{2}\\right)+\\beta\\max_{c_{3}\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c_{3}\\right)+\\beta v\\left(x-c_{1}-c_{2}-c_{3}\\right)\\right\\} \\right\\} \\right\\} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CakeEating:\n",
    "    def __init__(self,\n",
    "                 β=0.96,           # discount factor\n",
    "                 γ=1.5,            # degree of relative risk aversion\n",
    "                 x_grid_min=1e-3,  # exclude zero for numerical stability\n",
    "                 x_grid_max=2.5,   # size of cake\n",
    "                 x_grid_size=120):\n",
    "\n",
    "        self.β, self.γ = β, γ\n",
    "\n",
    "        # Set up grid\n",
    "        self.x_grid = np.linspace(x_grid_min, x_grid_max, x_grid_size)\n",
    "\n",
    "    # Utility function\n",
    "    def u(self, c):\n",
    "\n",
    "        γ = self.γ\n",
    "\n",
    "        if γ == 1:\n",
    "            return np.log(c)\n",
    "        else:\n",
    "            return (c ** (1 - γ)) / (1 - γ)\n",
    "\n",
    "    # first derivative of utility function\n",
    "    def u_prime(self, c):\n",
    "\n",
    "        return c ** (-self.γ)\n",
    "\n",
    "    def state_action_value(self, c, x, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation given x and c.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        u, β = self.u, self.β\n",
    "        v = lambda x: interp(self.x_grid, v_array, x)\n",
    "\n",
    "        return u(c[0]) + β * u(c[1]) + β ** 2 * v(x - c[0] - c[1])\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to solve the maximization problem\n",
    "def maximize(g, x0, args):  # Changed here\n",
    "    \"\"\"\n",
    "    Maximize the function g over the interval [a, b].\n",
    "\n",
    "    We use the fact that the maximizer of g on any interval is\n",
    "    also the minimizer of -g.  The tuple args collects any extra\n",
    "    arguments to g.\n",
    "\n",
    "    Returns the maximal value and the maximizer.\n",
    "    \"\"\"\n",
    "\n",
    "    objective = lambda x: -g(x, *args)\n",
    "    # Previously: result = minimize_scalar(objective, bounds=(a, b), method='bounded')\n",
    "    result = minimize(objective, x0, bounds=[[1e-10, args[0]], [1e-10, args[0]]], method='L-BFGS-B')  # Changed here\n",
    "    maximizer, maximum = result.x, -result.fun\n",
    "    return maximizer, maximum\n",
    "\n",
    "\n",
    "def T(v, ce):\n",
    "    \"\"\"\n",
    "    The Bellman operator.  Updates the guess of the value function.\n",
    "\n",
    "    * ce is an instance of CakeEating\n",
    "    * v is an array representing a guess of the value function\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "\n",
    "    for i, x in enumerate(ce.x_grid):\n",
    "        # Maximize RHS of Bellman equation at state x\n",
    "        x0 = np.array([x / 10, x/10])\n",
    "        v_new[i] = maximize(ce.state_action_value, x0, (x, v))[1]  # Changed here\n",
    "\n",
    "    return v_new\n",
    "\n",
    "\n",
    "def compute_value_function(ce,\n",
    "                           tol=1e-4,\n",
    "                           max_iter=1000,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    # Set up loop\n",
    "    v = np.zeros(len(ce.x_grid)) # Initial guess\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new = T(v, ce)\n",
    "\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"Error at iteration {i} is {error}.\")\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    if i == max_iter:\n",
    "        print(\"Failed to converge!\")\n",
    "\n",
    "    if verbose and i < max_iter:\n",
    "        print(f\"\\nConverged in {i} iterations.\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ce = CakeEating()\n",
    "v_new = compute_value_function(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trade-off:** Each iteration is \"closer to reality\" but more expensive to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, label='Iterate on $T$')\n",
    "ax.plot(x_grid, v_new, label=r\"Iterate on $T'$\")\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_title('Comparison between different methods')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Computing and High Performance Computing\n",
    "\n",
    "**Basic idea:** Use multiple \"computers\" at the same time\n",
    "\n",
    "First, stack the objects that need to be computed at a given iteration:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "Tv_{i+1}\\left(x_{1}\\right)&=&\\max_{c\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c\\right)+\\beta v_{i}\\left(x_{1}-c\\right)\\right\\} \\\\Tv_{i+1}\\left(x_{2}\\right)&=&\\max_{c\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c\\right)+\\beta v_{i}\\left(x_{2}-c\\right)\\right\\} \\\\\\vdots&\\vdots&\\vdots\\\\Tv_{i+1}\\left(x_{N}\\right)&=&\\max_{c\\in\\Gamma\\left(x\\right)}\\left\\{ u\\left(c\\right)+\\beta v_{i}\\left(x_{N}-c\\right)\\right\\} \n",
    "\\end{eqnarray}$$\n",
    "\n",
    "$Tv_{i+1}\\left(x_{1}\\right)$ and $Tv_{i+1}\\left(x_{1}\\right) $ can be computed **independently** so why not do them in parallel?\n",
    "\n",
    "#### Is this hard?\n",
    "\n",
    "It depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrote the code to work with Numba\n",
    "def bellman_operator_factory(x_grid, γ, β):\n",
    "    if γ == 1:\n",
    "        @njit\n",
    "        def u(c):\n",
    "            return np.log(c)    \n",
    "    else:\n",
    "        @njit\n",
    "        def u(c):\n",
    "            return (c ** (1 - γ)) / (1 - γ)\n",
    "    \n",
    "    @njit\n",
    "    def state_action_value(c, x, v_array):\n",
    "        \"\"\"\n",
    "        Right hand side of the Bellman equation given x and c.\n",
    "        \"\"\"\n",
    "        return u(c) + β * interp(x_grid, v_array, x - c)\n",
    "    \n",
    "    \n",
    "    @njit(parallel=True)  # Equivalent to T = njit(T, parallel=True)\n",
    "    def T(v):\n",
    "        \"\"\"\n",
    "        The Bellman operator.  Updates the guess of the value function.\n",
    "\n",
    "        * ce is an instance of CakeEating\n",
    "        * v is an array representing a guess of the value function\n",
    "\n",
    "        \"\"\"\n",
    "        v_new = np.empty_like(v)\n",
    "\n",
    "        for i in prange(len(x_grid)):\n",
    "            # Maximize RHS of Bellman equation at state x\n",
    "            v_new[i] = scalar_maximization.brent_max(state_action_value, 1e-10, x_grid[i], (x_grid[i], v))[1]\n",
    "\n",
    "        return v_new\n",
    "    \n",
    "    return T\n",
    "\n",
    "\n",
    "T = bellman_operator_factory(ce.x_grid, ce.γ, ce.β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_value_function(ce,\n",
    "                           tol=1e-4,\n",
    "                           max_iter=1000,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    # Set up loop\n",
    "    v = np.zeros(len(ce.x_grid)) # Initial guess\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    T = bellman_operator_factory(ce.x_grid, ce.γ, ce.β)\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new = T(v)\n",
    "\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"Error at iteration {i} is {error}.\")\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    if i == max_iter:\n",
    "        print(\"Failed to converge!\")\n",
    "\n",
    "    if verbose and i < max_iter:\n",
    "        print(f\"\\nConverged in {i} iterations.\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ce = CakeEating(x_grid_size=100_000)\n",
    "v_parallel = compute_value_function(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, label='base')\n",
    "ax.plot(x_grid, interp(ce.x_grid, v_parallel, x_grid), label=r\"parallel\")\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_title('Comparison between different methods')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More about parallel computing and HPC**\n",
    "\n",
    "- [Simon Scheidegger](https://sites.google.com/site/simonscheidegger/home)\n",
    "- https://github.com/sischei/OSE2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] John Stachurski, 2009. \"Economic Dynamics: Theory and Computation,\" MIT Press Books  \n",
    "[2] Johannes Brumm & Simon Scheidegger, 2017. \"Using Adaptive Sparse Grids to Solve High‐Dimensional Dynamic Models,\" Econometrica  \n",
    "[3] Artificial Intelligence as Structural Estimation: Economic Interpretations of Deep Blue, Bonanza, and AlphaGo, Mitsuru Igami  \n",
    "[4] Richard S. Sutton and Andrew G. Barto. 2018. Reinforcement Learning: An Introduction. A Bradford Book, Cambridge, MA, USA.  \n",
    "[5] [Daisuke Oyama's](http://www.oyama.e.u-tokyo.ac.jp/) excellent lecture notes on Dynamic Programming  \n",
    "[6] John Stachurski, 2008. \"Continuous State Dynamic Programming via Nonexpansive Approximation,\" Computational Economics  \n",
    "[7] Yongyang Cai & Kenneth Judd, 2013. \"Shape-preserving dynamic programming,\" Mathematical Methods of Operations Research  \n",
    "[8] Cai, Yongyang & Judd, Kenneth. (2014). Advances in Numerical Dynamic Programming and New Applications. Handbook of Computational Economics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
